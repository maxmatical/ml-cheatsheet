{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "full_twitter_sentiment_transformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxmatical/fast.ai/blob/master/full_twitter_sentiment_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMgx99NYbpIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/fastai/fastai.git\n",
        "!pip install transformers\n",
        "!pip install scikit-optimize\n",
        "!pip install optuna"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnCNplZFCBp4",
        "colab_type": "code",
        "outputId": "92563f79-7b52-41c9-ea71-d0e238076edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Set up environment and download course-v3\n",
        "!curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKq5YwwRCM5r",
        "colab_type": "code",
        "outputId": "39806dc7-e8ae-4062-b710-27ea72f67a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.utils.show_install import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "from transformers import AlbertForSequenceClassification, AlbertTokenizer, AlbertConfig\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
        "show_install()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "```text\n",
            "=== Software === \n",
            "python        : 3.6.9\n",
            "fastai        : 1.0.61.dev0\n",
            "fastprogress  : 0.2.2\n",
            "torch         : 1.4.0\n",
            "nvidia driver : 418.67\n",
            "torch cuda    : 10.1 / is available\n",
            "torch cudnn   : 7603 / is enabled\n",
            "\n",
            "=== Hardware === \n",
            "nvidia gpus   : 1\n",
            "torch devices : 1\n",
            "  - gpu0      : 15079MB | Tesla T4\n",
            "\n",
            "=== Environment === \n",
            "platform      : Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic\n",
            "distro        : #1 SMP Thu Aug 8 02:47:02 PDT 2019\n",
            "conda env     : Unknown\n",
            "python        : /usr/bin/python3\n",
            "sys.path      : \n",
            "/env/python\n",
            "/usr/lib/python36.zip\n",
            "/usr/lib/python3.6\n",
            "/usr/lib/python3.6/lib-dynload\n",
            "/usr/local/lib/python3.6/dist-packages\n",
            "/usr/lib/python3/dist-packages\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/extensions\n",
            "/root/.ipython\n",
            "```\n",
            "\n",
            "Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\n",
            "\n",
            "Optional package(s) to enhance the diagnostics can be installed with:\n",
            "pip install distro\n",
            "Once installed, re-run this utility to get the additional information\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbCUnF1cgj9f",
        "colab_type": "code",
        "outputId": "b269f447-df1d-4e06-8d41-def83695662d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "\n",
        "import fastai\n",
        "import transformers\n",
        "print('fastai version :', fastai.__version__)\n",
        "print('transformers version :', transformers.__version__)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai version : 1.0.61.dev0\n",
            "transformers version : 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYky0SyQCZPU",
        "colab_type": "text"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8bWDpNtCQNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('combined_tweets_clean.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLdscs8CCd--",
        "colab_type": "code",
        "outputId": "44b4902a-13de-4823-acb2-e337c8c247fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "print(len(df))\n",
        "\n",
        "df.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>date</th>\n",
              "      <th>id</th>\n",
              "      <th>location</th>\n",
              "      <th>name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2011-08-30 23:54</td>\n",
              "      <td>1.090000e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CPtte</td>\n",
              "      <td>Ok, I'm loving $GLD calls today, gold traders ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>bearish</td>\n",
              "      <td>2011-08-30 23:52</td>\n",
              "      <td>1.090000e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MichaelVlaicu</td>\n",
              "      <td>@auptimus if gold corrects I'd buy out dated g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>2011-08-30 23:16</td>\n",
              "      <td>1.090000e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>boposlav</td>\n",
              "      <td>What You Need to Know About the World's Larges...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>2011-08-30 23:08</td>\n",
              "      <td>1.090000e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ITMTrading</td>\n",
              "      <td>Ever wanted to know the difference between GLD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>2011-08-30 23:06</td>\n",
              "      <td>1.090000e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>iembot_gld</td>\n",
              "      <td>#GLD Area Forecast Discussion (AFD) http://t.c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                               text\n",
              "0           0  ...  Ok, I'm loving $GLD calls today, gold traders ...\n",
              "1           1  ...  @auptimus if gold corrects I'd buy out dated g...\n",
              "2           2  ...  What You Need to Know About the World's Larges...\n",
              "3           3  ...  Ever wanted to know the difference between GLD...\n",
              "4           4  ...  #GLD Area Forecast Discussion (AFD) http://t.c...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liW3zbbzCktu",
        "colab_type": "code",
        "outputId": "be8ae2a5-650c-4f9c-acd7-e912526c84b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "df['sentiment'].value_counts().plot(kind='bar')\n",
        "\n",
        "print(df['sentiment'].unique())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['neutral' 'bearish' 'unrelated' 'bullish']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEfCAYAAACtRRYAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XscVftJYDTQt",
        "colab_type": "text"
      },
      "source": [
        "Unrelated and neutral sentiments dominate the data currently (although this might not be the case in the future with the full dataset). It might be better to use a stratified sampling technique for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-GUhvxkELES",
        "colab_type": "code",
        "outputId": "70e12804-8516-4070-e2a4-d56cfff3d751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "sss.get_n_splits(df['text'], df['sentiment'])\n",
        "\n",
        "print(sss)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2,\n",
            "            train_size=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THDVEb8tFFGN",
        "colab_type": "code",
        "outputId": "8f1f6c9f-8327-4a4e-c610-6e9ed5af264c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_idx, val_idx = next(sss.split(df['text'], df['sentiment']))\n",
        "\n",
        "print(len(train_idx), len(val_idx))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14989 3748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnI14U3zKskb",
        "colab_type": "text"
      },
      "source": [
        "Verifying that the stratified split preseves the distribution of the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPqoB9P-JzhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df.iloc[train_idx, :]\n",
        "df_val = df.iloc[val_idx, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loavhYCJKdmz",
        "colab_type": "code",
        "outputId": "d75b9f66-b1e9-4281-fd08-c46fa24f0f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "df_train['sentiment'].value_counts().plot(kind='bar')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbdc12b3438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEfCAYAAACtRRYAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlbcSmFoBt8sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaoWfiBQKQG2",
        "colab_type": "code",
        "outputId": "9d01a31c-d80f-4f55-ee9f-0bb1c811d2fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "df_val['sentiment'].value_counts().plot(kind='bar')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbdc10865f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEfCAYAAACtRRYAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naEGsggAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrWWL-PxKiZt",
        "colab_type": "text"
      },
      "source": [
        "Looks like the distribution of the labels in train and val are the same, so we can start modelling now"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNDdmRdjhOcs",
        "colab_type": "text"
      },
      "source": [
        "# Setting up data for transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmsJcRyjhN6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr8kEitJhQik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "# seed = 42\n",
        "use_fp16 = False\n",
        "model_type = 'roberta'\n",
        "pretrained_model_name = 'roberta-base' # 'roberta-base-openai-detector'\n",
        "\n",
        "# model_type = 'bert'\n",
        "# pretrained_model_name='bert-base-uncased'\n",
        "\n",
        "# model_type = 'distilbert'\n",
        "# pretrained_model_name = 'distilbert-base-uncased-distilled-squad'#'distilbert-base-uncased'#'distilbert-base-uncased'\n",
        "\n",
        "#model_type = 'xlm'\n",
        "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
        "\n",
        "#model_type = 'xlnet'\n",
        "#pretrained_model_name = 'xlnet-base-cased'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRwrbj_ohUHO",
        "colab_type": "code",
        "outputId": "087c0328-7995-4bc4-e384-656e04ffefb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]\n",
        "model_class.pretrained_model_archive_map.keys()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM3QmtXYhg1h",
        "colab_type": "text"
      },
      "source": [
        "## Setting up tokenizer + numericalizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB_Mk2iFhaIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "        return [CLS] + tokens + [SEP]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufWfsFnzhl3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfKmo0fWhogF",
        "colab_type": "code",
        "outputId": "a717b83d-83a3-4878-fdab-6463fbfa0050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "tokenizer_class.pretrained_vocab_files_map"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'merges_file': {'distilroberta-base': 'https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-merges.txt',\n",
              "  'roberta-base': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt',\n",
              "  'roberta-base-openai-detector': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt',\n",
              "  'roberta-large': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt',\n",
              "  'roberta-large-mnli': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-merges.txt',\n",
              "  'roberta-large-openai-detector': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt'},\n",
              " 'vocab_file': {'distilroberta-base': 'https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-vocab.json',\n",
              "  'roberta-base': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json',\n",
              "  'roberta-base-openai-detector': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json',\n",
              "  'roberta-large': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json',\n",
              "  'roberta-large-mnli': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-vocab.json',\n",
              "  'roberta-large-openai-detector': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e42OyYUEhqav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "        #return self.tokenizer.encode(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KqWBee4hxz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
        "\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQZYkF0fh8yN",
        "colab_type": "text"
      },
      "source": [
        "## Setting up databunch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lralLwd8h7XE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elHGg4NTiBWd",
        "colab_type": "code",
        "outputId": "e2438ae1-3ab0-4abb-ddaa-60ef80bcc709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "bs = 32\n",
        "\n",
        "data_clas = (TextList.from_df(df, cols='text', processor=transformer_processor)\n",
        "             .split_by_idxs(train_idx, val_idx)\n",
        "             .label_from_df(cols= 'sentiment')\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtFBaIN9iolm",
        "colab_type": "code",
        "outputId": "cabdc835-fbb6-4dd2-8599-4d7aa303c759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
        "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
        "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
        "data_clas.show_batch()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] token : <s>\n",
            "[SEP] token : </s>\n",
            "[PAD] token : <pad>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; RT @ to pperc ool : @ day dev                                                            </td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; BU Y / ADD LONG - TER M : $ BTC - $ USD $ 7 , 8 37 . 86 - 149 . 98 (- 1 . 88 %)  # Bitcoin # USD # Crypt oc urrency  10 : 00 AM 5 / 20 / 19   $ us du $ u up $ cy b $ y inn $ yang $ cn $ chn</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; 2019 Returns ... Which one do you have ?     Bitcoin $ BTC : + 116 %  Oil $ US O : + 33 %  RE IT s $ V N Q : + 18 %  N as daq 100 $ Q Q Q : + 17 %  Small Caps $ I WM : + 14 %  S &amp; amp ;</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; @ cz _ bin ance @ bin ance @ B inance _ D EX @ Zen Go Congratulations to @ bin ance team . It pays off !   2019 Returns !  # Crypt o is the future   B inance Coin : + 300 % $ bnb  L ite coin : + 175 % $ lt c  Bitcoin Cash : + 136 %</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; More # Trade H acks in my # ebook s :  https :// t . co / U q ee J kr q U f    $ ES _ F $ N Q _ F $ Z B _ F $ SP X $ R UT $ A AP L $ NFL X $ AM Z N $ TS LA $ V IX $ FB $</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KApZcW2iiynP",
        "colab_type": "code",
        "outputId": "7bc86085-1b42-4209-b645-e75cee0e97e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# checking batch and numericalizer\n",
        "\n",
        "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
        "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
        "print('[PAD] id :', pad_idx)\n",
        "test_one_batch = data_clas.one_batch()[0]\n",
        "print('Batch shape : ',test_one_batch.shape)\n",
        "print(test_one_batch)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] id : 0\n",
            "[SEP] id : 2\n",
            "[PAD] id : 1\n",
            "Batch shape :  torch.Size([32, 202])\n",
            "tensor([[    0, 10541,   787,  ..., 24107,  5543,     2],\n",
            "        [    0, 10541,   787,  ...,     1,     1,     1],\n",
            "        [    0,   436,    16,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,   849, 20439,  ...,     1,     1,     1],\n",
            "        [    0,    68,   530,  ...,     1,     1,     1],\n",
            "        [    0,   370,    64,  ...,     1,     1,     1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ye6u9YhjAjH",
        "colab_type": "text"
      },
      "source": [
        "# RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGhkWAqii4ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, transformer_model: PreTrainedModel):\n",
        "        super(CustomTransformerModel,self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \n",
        "        #attention_mask = (input_ids!=1).type(input_ids.type()) # Test attention_mask for RoBERTa\n",
        "        \n",
        "        logits = self.transformer(input_ids,\n",
        "                                attention_mask = attention_mask)[0]   \n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v7nVxGbjdG9",
        "colab_type": "code",
        "outputId": "e4ec22ba-0595-4269-8537-280f68454906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        }
      },
      "source": [
        "n_labels = 4\n",
        "\n",
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "config.num_labels = n_labels\n",
        "config.use_bfloat16 = use_fp16\n",
        "print(config)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 4,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1hSeT81jhdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
        "\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Twth-Kqj_MA",
        "colab_type": "text"
      },
      "source": [
        "## Creating learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30kj8X6Vjl-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AdamW\n",
        "# from ranger import Ranger"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "041rlFxl_9fx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optar = partial(Ranger)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck8Xd9S_kGbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try: \n",
        "    learn.destroy()\n",
        "except:\n",
        "    'no learner created'\n",
        "\n",
        "learn = Learner(data_clas,\n",
        "               custom_transformer_model,\n",
        "               opt_func = lambda input: AdamW(input,correct_bias=False, eps = 1e-4),\n",
        "            #   opt_func = optar,\n",
        "               loss_func = FlattenedLoss(LabelSmoothingCrossEntropy, axis=-1),\n",
        "               metrics = [accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPJZb0kUkd80",
        "colab_type": "text"
      },
      "source": [
        "### Creating layer splitting for gradual unfreezing and discriminative learning rates\n",
        "\n",
        "use   \"num_hidden_layers\" in config + 2 (1 for embedding and 1 for head)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjACE6gekRxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For roberta-base\n",
        "list_layers = [learn.model.transformer.roberta.embeddings,\n",
        "              learn.model.transformer.roberta.encoder.layer[0],\n",
        "              learn.model.transformer.roberta.encoder.layer[1],\n",
        "              learn.model.transformer.roberta.encoder.layer[2],\n",
        "              learn.model.transformer.roberta.encoder.layer[3],\n",
        "              learn.model.transformer.roberta.encoder.layer[4],\n",
        "              learn.model.transformer.roberta.encoder.layer[5],\n",
        "              learn.model.transformer.roberta.encoder.layer[6],\n",
        "              learn.model.transformer.roberta.encoder.layer[7],\n",
        "              learn.model.transformer.roberta.encoder.layer[8],\n",
        "              learn.model.transformer.roberta.encoder.layer[9],\n",
        "              learn.model.transformer.roberta.encoder.layer[10],\n",
        "              learn.model.transformer.roberta.encoder.layer[11],\n",
        "              learn.model.transformer.roberta.pooler]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1EMlOm6kr22",
        "colab_type": "code",
        "outputId": "a46fde76-e8c9-48e9-fec1-6b56b957635f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check groups\n",
        "learn.split(list_layers)\n",
        "num_groups = len(learn.layer_groups)\n",
        "print('Learner split in',num_groups,'groups')\n",
        "# print(learn.layer_groups)\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learner split in 14 groups\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBjFUqKQxgdh",
        "colab_type": "text"
      },
      "source": [
        "Optional: Freeze the model to train the head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK12C4yxk7vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn.freeze();\n",
        "\n",
        "learn.unfreeze();\n",
        "learn.summary();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBlWmpdrlJxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn.lr_find()\n",
        "# learn.recorder.plot(suggestion = True, skip_end=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6PHHECClV1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.to_fp16()\n",
        "\n",
        "lr_init = 3e-5\n",
        "lr = lr_init\n",
        "\n",
        "\"\"\"Training without adjusting the momentum\"\"\"\n",
        "learn.fit_one_cycle(3, \n",
        "                    lr, \n",
        "                    pct_start = 0.3,\n",
        "                    callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "                                                 name='classifier_stage1')])\n",
        "\n",
        "\"\"\"Training discriminative learning rates\"\"\"\n",
        "# learn.fit_one_cycle(5, \n",
        "#                     slice(lr/10, lr), \n",
        "#                     callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "#                                                  name='classifier_stage1')])\n",
        "\"\"\"\n",
        "Clipping momentum\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# learn.fit_one_cycle(10, \n",
        "#                     lr, \n",
        "#                     moms=(0.8,0.7),\n",
        "#                     callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "#                                                  name='classifier_stage1')])\n",
        "\n",
        "\"\"\"Training Ranger\"\"\"\n",
        "# learn.fit_fc(3, \n",
        "#             lr, \n",
        "#             callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "#                                         name='classifier_stage1')])\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Warmup cosine with restarts\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def fit_cosine_restart(learn, n_cycles, lr, mom, cycle_len, cycle_mult):\n",
        "    n = len(learn.data.train_dl)\n",
        "    phases = [(TrainingPhase(n * (cycle_len * cycle_mult**i))\n",
        "                 .schedule_hp('lr', lr, anneal=annealing_cos)) for i in range(n_cycles)]\n",
        "    sched = GeneralScheduler(learn, phases)\n",
        "    learn.callbacks.append(sched)\n",
        "    if cycle_mult != 1:\n",
        "        total_epochs = int(cycle_len * (1 - (cycle_mult)**n_cycles)/(1-cycle_mult)) \n",
        "    else: total_epochs = n_cycles * cycle_len\n",
        "\n",
        "    learn.fit(total_epochs, \n",
        "              callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "                                                 name='classifier_stage1')])\n",
        "\n",
        "# fit_cosine_restart(learn, 15, lr, 0.9, 1, 2)\n",
        "\n",
        "\n",
        "learn.recorder.plot_losses()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY-O__onPn31",
        "colab_type": "text"
      },
      "source": [
        "**Results**\n",
        "\n",
        "approx 85.3% accuracy training unfrozen model (without discriminative learning rate) for 5 epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U2u6mCmlgMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try: \n",
        "    learn.load('classifier_stage1')\n",
        "except:\n",
        "    print('no learner created')\n",
        "learn.unfreeze();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V_AlPPZ7TB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot(suggestion = True, skip_end=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k13jU0KIqaIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 3e-5\n",
        "\"\"\"Training without adjusting the momentum\"\"\"\n",
        "# learn.fit_one_cycle(10, \n",
        "#                     slice(lr/100,lr/10),\n",
        "#                     pct_start = 0.3, \n",
        "#                     callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "#                                                  name='classifier_stage2')])\n",
        "\n",
        "# \"\"\"Training discriminative learning rates\"\"\"\n",
        "# learn.fit_one_cycle(5, \n",
        "#                     slice(lr/10, lr), \n",
        "#                     callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "#                                                  name='classifier_stage1')])\n",
        "\"\"\"\n",
        "Clipping momentum\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# learn.fit_one_cycle(10, \n",
        "#                     lr, \n",
        "#                     moms=(0.8,0.7),\n",
        "#                     callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "#                                                  name='classifier_stage1')])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Training Ranger\n",
        "\n",
        "\"\"\"\n",
        "learn.fit_fc(10, \n",
        "            lr/10, \n",
        "            callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "                                        name='classifier_stage1')])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "cosine anneal with restarts\n",
        "\"\"\"\n",
        "# fit_cosine_restart(learn, 5, lr, 0.9, 1, 2)\n",
        "\n",
        "\n",
        "learn.recorder.plot_losses()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er5hmarEXYuO",
        "colab_type": "text"
      },
      "source": [
        "### Getting validation accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lfy1g8yaopm",
        "colab_type": "text"
      },
      "source": [
        "1st way: using learn.get_preds() and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz0Vqm9LXaMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds, y, losses = learn.get_preds(ds_type=DatasetType.Valid, with_loss = True)\n",
        "print(accuracy(preds, y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f2J2JQParAP",
        "colab_type": "text"
      },
      "source": [
        "2nd way: using learn.validate()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDgEUraUqvhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_accuracy = learn.validate(learn.data.valid_dl)[1].numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c22cWi50aJfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(val_accuracy)\n",
        "type(val_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORThkO8lwkEb",
        "colab_type": "text"
      },
      "source": [
        "# Exporting Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aIy3scYwuTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas.save()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fbZna9lwmtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.export('roberta.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVtFnHj2LNwH",
        "colab_type": "text"
      },
      "source": [
        "# Loading Inference Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjUl1BDLLPx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try: \n",
        "    learn.destroy()\n",
        "except:\n",
        "    'no learner created'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxcbkzRDLdeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = load_learner(path = '/content', file = 'roberta.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kucgFsT3LtjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.predict('I really loved that $GLD!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVSwKLk-B6GB",
        "colab_type": "text"
      },
      "source": [
        "This returns an error due to tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRFf_DPKbGTs",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparam tuning with Hyperband"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq1NzEGsZYQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from hyperband import hyperband\n",
        "from skopt.space import Integer, Real, Categorical\n",
        "space = [\n",
        "         Real(0.05, 0.9, name = 'pct_start'),\n",
        "         Real(0.8, 0.9, name = 'b1'),\n",
        "         Real(0.7, 0.999, name = 'b2')\n",
        "]\n",
        "\n",
        "# add hyperparams from space here\n",
        "def fit_and_score(resources, checkpoint, pct_start, b1, b2):\n",
        "    import warnings\n",
        "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "    learn = Learner(data_clas,\n",
        "            custom_transformer_model,\n",
        "            opt_func = lambda input: AdamW(input,correct_bias=False),\n",
        "            loss_func = FlattenedLoss(LabelSmoothingCrossEntropy, axis=-1),\n",
        "            metrics = [accuracy])\n",
        "    \n",
        "    learn.to_fp16()\n",
        "\n",
        "    lr = 3e-5\n",
        "    learn.fit_one_cycle(1, \n",
        "                lr,\n",
        "                pct_start = pct_start,\n",
        "                moms = (b1, b2),\n",
        "                callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "                                                name='classifier_stage1')])\n",
        "\n",
        "    val_accuracy = learn.validate(learn.data.valid_dl)[1].numpy()\n",
        "\n",
        "    # Maximisation problem\n",
        "    return - val_accuracy, [pct_start, b1, b2]\n",
        "\n",
        "\n",
        "accuracies, hps = hyperband(objective=fit_and_score, dimensions=space)\n",
        "for acc, hp in zip(accuracies, hps):\n",
        "    print(acc, hp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntfPUsQEaAKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk2_CLoJBgIh",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparam Tuning with Optuna (TPE + Hyperband Pruner)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAc2tdx5HSVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import optuna\n",
        "from optuna.integration import FastAIPruningCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLisshy1HS8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(trial):\n",
        "    lr = trial.suggest_uniform('lr', 1e-6, 5e-5)\n",
        "    pct_start = trial.suggest_uniform('pct_start', 0.1, 0.8)\n",
        "    b1 = trial.suggest_uniform('b1', 0.8, 0.9)\n",
        "    b2 = trial.suggest_uniform('b2', 0.7, 0.999)\n",
        "\n",
        "    try: \n",
        "        learn.destroy()\n",
        "    except:\n",
        "        'no learner created'\n",
        "\n",
        "    learn = Learner(data_clas,\n",
        "        custom_transformer_model,\n",
        "        opt_func = lambda input: AdamW(input,correct_bias=False),\n",
        "        loss_func = FlattenedLoss(LabelSmoothingCrossEntropy, axis=-1),\n",
        "        metrics = [accuracy],\n",
        "        callback_fns=[partial(FastAIPruningCallback, trial=trial, monitor='valid_loss')])\n",
        "    \n",
        "    \n",
        "    learn.to_fp16()\n",
        "\n",
        "    learn.fit_one_cycle(3, \n",
        "                lr,\n",
        "                pct_start = pct_start,\n",
        "                moms = (b1, b2))\n",
        "\n",
        "    return learn.validate()[-1].item() # returns accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgv1birqJ2nE",
        "colab_type": "text"
      },
      "source": [
        "Run study"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5YwpvVeBhkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "adea9a1c-eff7-4670-f526-454693140e1c"
      },
      "source": [
        "pruner = optuna.pruners.HyperbandPruner()\n",
        "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
        "study.optimize(objective, n_trials=100, timeout=600)\n",
        "print('Number of finished trials: {}'.format(len(study.trials)))\n",
        "\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "\n",
        "print('  Value: {}'.format(trial.value))\n",
        "\n",
        "print('  Params: ')\n",
        "for key, value in trial.params.items():\n",
        "    print('    {}: {}'.format(key, value))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.640105</td>\n",
              "      <td>0.715568</td>\n",
              "      <td>0.826307</td>\n",
              "      <td>01:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.667681</td>\n",
              "      <td>0.743865</td>\n",
              "      <td>0.817236</td>\n",
              "      <td>01:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.526961</td>\n",
              "      <td>0.696700</td>\n",
              "      <td>0.840715</td>\n",
              "      <td>01:26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-02-07 19:43:53,318]\u001b[0m Finished trial#0 resulted in value: 0.8407150506973267. Current best value is 0.8407150506973267 with parameters: {'lr': 4.557823755985217e-05, 'pct_start': 0.6205262673633526, 'b1': 0.82969909167548, 'b2': 0.8208021195079481}.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.612991</td>\n",
              "      <td>0.719741</td>\n",
              "      <td>0.828442</td>\n",
              "      <td>01:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.514473</td>\n",
              "      <td>0.700135</td>\n",
              "      <td>0.843116</td>\n",
              "      <td>01:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.459564</td>\n",
              "      <td>0.700648</td>\n",
              "      <td>0.849253</td>\n",
              "      <td>01:27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-02-07 19:48:19,478]\u001b[0m Finished trial#1 resulted in value: 0.8492529392242432. Current best value is 0.8492529392242432 with parameters: {'lr': 3.77348950908529e-05, 'pct_start': 0.2932869541372414, 'b1': 0.8159444533729066, 'b2': 0.9049508208089048}.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.493120</td>\n",
              "      <td>0.717389</td>\n",
              "      <td>0.845784</td>\n",
              "      <td>01:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.459763</td>\n",
              "      <td>0.714205</td>\n",
              "      <td>0.848719</td>\n",
              "      <td>01:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.440128</td>\n",
              "      <td>0.721334</td>\n",
              "      <td>0.851921</td>\n",
              "      <td>01:28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-02-07 19:52:48,072]\u001b[0m Finished trial#2 resulted in value: 0.851921021938324. Current best value is 0.851921021938324 with parameters: {'lr': 2.3431953320996176e-05, 'pct_start': 0.36404500692646136, 'b1': 0.8287696895626827, 'b2': 0.9090276895955027}.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of finished trials: 3\n",
            "Best trial:\n",
            "  Value: 0.851921021938324\n",
            "  Params: \n",
            "    lr: 2.3431953320996176e-05\n",
            "    pct_start: 0.36404500692646136\n",
            "    b1: 0.8287696895626827\n",
            "    b2: 0.9090276895955027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyA4KbFGIC2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9671d276-5183-4461-8084-70dc22e2d194"
      },
      "source": [
        "try: \n",
        "    learn.destroy()\n",
        "except:\n",
        "    'no learner created'\n",
        "\n",
        "learn = Learner(data_clas,\n",
        "               custom_transformer_model,\n",
        "               opt_func = lambda input: AdamW(input,correct_bias=False, eps = 1e-4),\n",
        "               loss_func = FlattenedLoss(LabelSmoothingCrossEntropy, axis=-1),\n",
        "               metrics = [accuracy])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this Learner object self-destroyed - it still exists, but no longer usable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5ncx5XxNjzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d45db2e4-fb53-47df-8177-b1dd56bfc36d"
      },
      "source": [
        "learn.to_fp16()\n",
        "\n",
        "lr = 2.34e-5\n",
        "pct_start = 0.364\n",
        "b1 = 0.83\n",
        "b2 = 0.91\n",
        "learn.fit_one_cycle(5, \n",
        "            lr,\n",
        "            pct_start = pct_start,\n",
        "            moms = (b1, b2),\n",
        "            callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "                                                name='classifier_optuna')])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.432903</td>\n",
              "      <td>0.731410</td>\n",
              "      <td>0.851121</td>\n",
              "      <td>01:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.446230</td>\n",
              "      <td>0.758373</td>\n",
              "      <td>0.844984</td>\n",
              "      <td>01:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.442822</td>\n",
              "      <td>0.731881</td>\n",
              "      <td>0.844450</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.421624</td>\n",
              "      <td>0.734303</td>\n",
              "      <td>0.849253</td>\n",
              "      <td>01:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.409585</td>\n",
              "      <td>0.739078</td>\n",
              "      <td>0.850587</td>\n",
              "      <td>01:28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with accuracy value: 0.8511205911636353.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F83BpLSnN7Ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}